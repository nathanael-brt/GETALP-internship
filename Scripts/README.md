# Scripts
## User Manual

### Audio2txtgrid

This script simultaneously launches Whisper on a given audio file, creates the necessary files/directories, and translates the newly generated `.srt` file into a `.TextGrid` file (by executing the [whisper2txtgrid](../Python_Programs/README.md#whisper2txtgrid) Python program).  
It takes 2 inputs (read from the keyboard during the script's execution):   
* The audio file to be transcribed.  
* The model of Whisper to use.  

When executing the `whisper2txtgrid.py` program, 2 files are needed as inputs; these files have been created earlier in the script:   
* The `.srt` file has been created in the *"srt"* folder.   
* The `.TextGrid` file has been created in the *"Textgrid"* folder.
These files have the same name as the audio file. 

The script also creates a folder in the *"Whisper"* folder, whose name is the same as the name of the audio file. This is where all the files generated by Whisper will be kept. 

--------------------------------------------------------------------------------------------
### plsppWER

This script computes the WER of the transcription from PLSPP.  

**/!\\** To work correctly, this script needs PLSPP to be installed in this directory: *"../plspp"*, as well as the `intervalles2wavAndtimetable.praat` script to be in the *"plspp/scripts"* directory.    

The script has the option to launch PLSPP (via the `plspp.sh` script); it will ask the user if they want to launch it or not. If you decide not to launch PLSPP, you need to have the data you want to work on inside the PLSPP folders. 

It also needs the `timeInfo.csv` file, which provides information on the timing of each PLSPP segment in this format:

```csv
File;Speaker;Segment;Start;End;Duration
<name_of_the_file1>.wav;SPEAKER_01;<name_of_the_file1>_SPEAKER_01_0;<start_timing>;<end_timing>;<duration>
...
<name_of_the_filen>.wav;SPEAKER_m;<name_of_the_filen>_SPEAKER_m_k;<start_timing>;<end_timing>;<duration>
```
If you launch the pipeline, this file is generated automatically; otherwise, it needs to be stored in the directory *"PLSPP_WER/TimeInfo"*.

When executing the script, it is possible to decide whether to launch PSLPP or not. It then transfers all the necessary files into the correct directories, sorts the `timeInfo.csv` file into the `timeInfo_sorted.csv` file, then calls [PipeFormat4WER.py](../Python_Programs/README.md#PipeFormat4WER), [TrueSegmentation.py](../Python_Programs/README.md#TrueSegmentation), and [WER.py](../Python_Programs/README.md#WER) on each file to compute the WER.

If the script detects that the WER is too high (â‰¥0.9), it considers there is an error, changes the order of the speaker, and recomputes the WER.

--------------------------------------------------------------------------------------------
### ProsodicDataFromCorpus

This script allows launching PLSPP_MFA but replaces the WhisperX step output with the text from the gold corpus to have a manual transcription instead of an automatic one.

To work, it needs PLSPP to be installed in the *"../plspp/"* directory. It also needs [MFA](https://montreal-forced-aligner.readthedocs.io/) to align the text. 
It also needs the `intervalles2wavAndtimetable.praat` script to be in the *"plspp/scripts"* directory.

It first creates and transfers the files necessary to PLSPP_MFA using [MFA_segmented_files.py](../Python_Programs/README.md#MFA_segmented_files) and then launches the pipeline without the transcription part.
