# GETALP-internship

This repository was created during an internship in the *GETALP* team at the Grenoble computer science laboratory (*LIG*). The subject of this internship was:

**Evaluation of the automatic analysis of French accent in English**.

The aim was to implement **speech transcription** and **analysis** tools, verify and correct the systems' outputs, and evaluate the automatic analysis tools on these manually validated annotations.

----------------------------------------------------------------------------------------------------

* Based on this tool: [plspp](https://gricad-gitlab.univ-grenoble-alpes.fr/lidilem/plspp) and [OpenAI's Whisper](https://github.com/openai/whisper).
* Important data is stored and organized [here](https://docs.google.com/spreadsheets/d/1V8g1R39eb_w_HWZOjSdOJWTzMdefQilUtBhCA2uvhWg/edit?usp=sharing).
* Shell scripts are located [here](Scripts/).
* Python programs are located [here](Python_Programs/).

----------------------------------------------------------------------------------------------------

**It has been divided into 4 main steps**:

## Transcription from Whisper and Computation of the WER

Since the PLSPP pipeline relies on OpenAI's Whisper transcription tool, the initial objective was to test this tool. This involved computing the Word Error Rate (WER) on a sample of audio files, comparing the transcription hypothesis generated by Whisper with manually provided references. Simultaneously, it also facilitated the creation of a *gold corpus*—a meticulously hand-transcribed corpus guaranteed to be accurate—for use as a reference.

[See more](Whisper_WER/)

## Transcription from PLSPP and Computation of the WER

Following individual testing of the PLSPP base, the goal was to evaluate the entire pipeline and observe the impact of transcription quality on subsequent measurements.

PLSPP transcribes audio recordings by segmenting them into smaller segments based on speaker identity. Transcription is conducted using WhisperX, but only for segments longer than 8 seconds. This segmentation approach may introduce contextual losses that could potentially impact speech understanding. Therefore, it is crucial to assess whether transcription quality is affected by these contextual losses by calculating the Word Error Rate (WER) of the text produced by PLSPP.

[See more](PLSPP_WER/)

## Impact of Transcription on Prosodic Measures

One of PLSPP's primary features is measuring prosody and lexical stress (i.e., accentuation). However, to compute these measurements, PLSPP relies on a transcription performed by [WhisperX](https://github.com/m-bain/whisperX). Therefore, evaluating the influence of transcription quality on the prosodic results provided by PLSPP is pertinent. This evaluation will also provide insights into how the accents of French speakers behave in English, based on data provided by WhisperX.

[See more](PLSPP_Prosodic/)

## Comparison of Models and Carbon Emissions

Whisper is a tool trained on various models, some more resource-intensive than others. In theory, heavier models are expected to yield better results. This section aims to test this hypothesis while also calculating the CO2 emissions associated with each model, thereby evaluating the practicality of using heavier models in PLSPP.

[See more](emissions/)
